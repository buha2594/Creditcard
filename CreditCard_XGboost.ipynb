{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59ea24c0-d108-4b1f-bd2b-ced0626f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, classification_report, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ea321cb-3e6d-43da-bb6a-f9e3d17c4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/cdrive/desktop/DIVYA/CAREER/guvi/PROJECT/CREDIT_CARD/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba683e5-018b-438b-abe0-02b0a2290fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis data is about the credit card fraud transactions.\\nClass column having 0 indicates a normal transaction.\\nClass column having 1 indicates a fraud transaction.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This data is about the credit card fraud transactions.\n",
    "Class column having 0 indicates a normal transaction.\n",
    "Class column having 1 indicates a fraud transaction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c9d4e1f-96c3-45c7-a9f4-b08873696f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "132bc695-140c-4fe1-9550-b720da915ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (284807, 31)\n",
      "Rows : 284807\n",
      "Columns : 31\n"
     ]
    }
   ],
   "source": [
    "# Getting the shape of the data\n",
    "print('Shape :', df.shape)\n",
    "print('Rows :', df.shape[0])\n",
    "print('Columns :', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16df1e80-111b-4dc3-ae3e-9e7fac4168c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2437347-8b04-4c0a-bb54-540d6b3771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c19037e4-3fb0-420a-a619-b3bf2d77ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd642679-4c7f-4dba-82fe-a38e13c15434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about null values\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85a64b85-8353-461f-a7ee-15a1e1e856db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the amount column\n",
    "df['normAmount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\n",
    "\n",
    "# Dropping the columns\n",
    "df.drop(['Time', 'Amount'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3320add-459e-48cb-a4aa-53001d046cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.9983\n",
       "1    0.0017\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the proportion of values from 'Class' column\n",
    "df['Class'].value_counts(normalize = True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfcd2731-9f72-47c8-b24a-25e29bff154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 99.83% of the data from Class 0\n",
    "# We have 0.17% of the data from Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdcc7446-6083-43a1-a193-7807cd0b6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above data indicates that there is a huge amount of imbaalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4de2c842-c9e9-4604-bcb0-d8d3c972531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating input features and target variable\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "# Performing train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1876c664-2b5a-420e-98f7-bb89a8f8f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "xgb_clf = XGBClassifier(random_state=5, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Fitting the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting from the model (Testing Data)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Predicting from the model (Training Data)\n",
    "y_train_pred = xgb_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6edb31c-fb30-4189-9b67-b913e68fd742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 1.0\n",
      "Testing Precision : 0.97\n",
      "Testing Recall : 0.84\n",
      "Testing F1 Score : 0.9\n",
      "\n",
      "Training Accuracy : 1.0\n",
      "Training Precision : 1.0\n",
      "Training Recall : 1.0\n",
      "Training F1 Score : 1.0\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.97      0.84      0.90        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.92      0.95     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "# Testing Dataset\n",
    "print('Testing Accuracy :', np.round(metrics.accuracy_score(y_test, y_pred), 2))\n",
    "print('Testing Precision :', np.round(metrics.precision_score(y_test, y_pred), 2))\n",
    "print('Testing Recall :', np.round(metrics.recall_score(y_test, y_pred), 2))\n",
    "print('Testing F1 Score :', np.round(metrics.f1_score(y_test, y_pred), 2))\n",
    "\n",
    "# Training Dataset\n",
    "print('\\nTraining Accuracy :', np.round(metrics.accuracy_score(y_train, y_train_pred), 2))\n",
    "print('Training Precision :', np.round(metrics.precision_score(y_train, y_train_pred), 2))\n",
    "print('Training Recall :', np.round(metrics.recall_score(y_train, y_train_pred), 2))\n",
    "print('Training F1 Score :', np.round(metrics.f1_score(y_train, y_train_pred), 2))\n",
    "print(\"\\n Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f590-c4e4-456c-8340-69e1b5531490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "XGBoost model achieves 100% accuracy on the test set, indicating potential overfitting,\n",
    "as the training accuracy is also perfect. \n",
    "While precision (97%) for fraud detection is high (few false alarms), recall (84%) shows that 16% of fraud cases are missed,\n",
    "which could be critical in real-world scenarios. \n",
    "The F1-score (0.90) suggests a good balance, but improving recall is crucial.\n",
    "The model performs exceptionally well for legitimate transactions (class 0), \n",
    "but class imbalance still affects fraud detection.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aea768f9-f452-436e-b507-ad75210014ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_res shape: (453204, 29)\n",
      "y_train_res shape: (453204,)\n",
      "X_test shape: (56746, 29)\n",
      "y_test shape: (56746,)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best Hyperparameters: {'colsample_bytree': 0.6557975442608167, 'gamma': 0.14607232426760908, 'learning_rate': 0.1199085529881075, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 157, 'reg_lambda': 0.6142344384136116, 'subsample': 0.836965827544817}\n",
      "Hyperparameter Tuning Time: 137.16 seconds\n",
      "\n",
      "\n",
      "Training Set Evaluation Metrics:\n",
      "Accuracy  : 1.0000\n",
      "Precision : 1.0000\n",
      "Recall    : 1.0000\n",
      "F1 Score  : 1.0000\n",
      "\n",
      "Testing Set Evaluation Metrics:\n",
      "Accuracy  : 0.9992\n",
      "Precision : 0.9992\n",
      "Recall    : 0.9992\n",
      "F1 Score  : 0.9992\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.74      0.79      0.77        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.87      0.89      0.88     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import randint, uniform  \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE\n",
    "\n",
    "# Load or Prepare Dataset\n",
    "# Assuming X and y are already preprocessed feature matrix and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Debugging: Check dataset sizes\n",
    "print(\"X_train_res shape:\", X_train_res.shape)\n",
    "print(\"y_train_res shape:\", y_train_res.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),          \n",
    "    'learning_rate': uniform(0.01, 0.3),       \n",
    "    'max_depth': randint(3, 10),               \n",
    "    'min_child_weight': randint(1, 10),        \n",
    "    'subsample': uniform(0.6, 0.4),            \n",
    "    'colsample_bytree': uniform(0.6, 0.4),     \n",
    "    'gamma': uniform(0, 0.5),                  \n",
    "    'reg_lambda': uniform(0.1, 1.0)            \n",
    "}\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='f1',  \n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Start Timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model with resampled training data\n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# End Timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Best Hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "print(f\"Hyperparameter Tuning Time: {end_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "# Train Final Model with Best Parameters\n",
    "best_xgb = XGBClassifier(**best_params, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "best_xgb.fit(X_train_res, y_train_res)  # Use SMOTE data\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_xgb.predict(X_train_res)\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Model Evaluation - Training Data\n",
    "print(\"\\nTraining Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_train_res, y_train_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "\n",
    "# Model Evaluation - Testing Data\n",
    "print(\"\\nTesting Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff15b4-7e5c-4301-82f7-535282ddf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "XGBoost model achieves 99.92% accuracy, but this is mainly due to the dominance of legitimate transactions.\n",
    "The training metrics (100%) indicate overfitting, suggesting the model has memorized the data.\n",
    "Fraud detection (Class 1) shows 74% precision and 79% recall, meaning some fraud cases are missed,\n",
    "and false positives exist. SMOTE improved recall, but the model still leans toward the majority class..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12dd578f-0231-45ed-8e68-d939d5b6c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_res shape: (453241, 29)\n",
      "y_train_res shape: (453241,)\n",
      "X_test shape: (56746, 29)\n",
      "y_test shape: (56746,)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "Best Hyperparameters: {'colsample_bytree': 0.6849356442713105, 'gamma': 0.09091248360355031, 'learning_rate': 0.06502135295603015, 'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 138, 'reg_lambda': 0.3912291401980419, 'subsample': 0.8447411578889518}\n",
      "Hyperparameter Tuning Time: 108.72 seconds\n",
      "\n",
      "\n",
      "Training Set Evaluation Metrics:\n",
      "Accuracy  : 0.9979\n",
      "Precision : 0.9979\n",
      "Recall    : 0.9979\n",
      "F1 Score  : 0.9979\n",
      "\n",
      "Testing Set Evaluation Metrics:\n",
      "Accuracy  : 0.9952\n",
      "Precision : 0.9984\n",
      "Recall    : 0.9952\n",
      "F1 Score  : 0.9965\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.24      0.83      0.37        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.62      0.91      0.68     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN   \n",
    "\n",
    "# Load or Prepare Dataset\n",
    "# Assuming X and y are already preprocessed feature matrix and labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Apply ADASYN to handle class imbalance\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Debugging: Check dataset sizes\n",
    "print(\"X_train_res shape:\", X_train_res.shape)\n",
    "print(\"y_train_res shape:\", y_train_res.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),          \n",
    "    'learning_rate': uniform(0.01, 0.3),       \n",
    "    'max_depth': randint(3, 10),               \n",
    "    'min_child_weight': randint(1, 10),        \n",
    "    'subsample': uniform(0.6, 0.4),            \n",
    "    'colsample_bytree': uniform(0.6, 0.4),     \n",
    "    'gamma': uniform(0, 0.5),                  \n",
    "    'reg_lambda': uniform(0.1, 1.0)            \n",
    "}\n",
    "\n",
    "# Initialize XGBoost Classifier\n",
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='f1',  \n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Start Timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model with resampled training data\n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# End Timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Best Hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "print(f\"Hyperparameter Tuning Time: {end_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "# Train Final Model with Best Parameters\n",
    "best_xgb = XGBClassifier(**best_params, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "best_xgb.fit(X_train_res, y_train_res)  # Use SMOTE data\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_xgb.predict(X_train_res)\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Model Evaluation - Training Data\n",
    "print(\"\\nTraining Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_train_res, y_train_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_train_res, y_train_pred, average='weighted'):.4f}\")\n",
    "\n",
    "# Model Evaluation - Testing Data\n",
    "print(\"\\nTesting Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_test, y_test_pred, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e74556-410d-4e81-bba2-462ca967fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The model achieves 99.52% accuracy, correctly classifying most transactions, but struggles with fraud detection.\n",
    "High recall (83%) for fraud cases means it detects most frauds, but low precision (24%) indicates many false positives. \n",
    "Legitimate transactions (Class 0) are almost perfectly classified, but fraud detection needs improvement. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
