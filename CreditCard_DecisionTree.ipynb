{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59ea24c0-d108-4b1f-bd2b-ced0626f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, classification_report, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea321cb-3e6d-43da-bb6a-f9e3d17c4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/cdrive/desktop/DIVYA/CAREER/guvi/PROJECT/CREDIT_CARD/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba683e5-018b-438b-abe0-02b0a2290fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This data is about the credit card fraud transactions.\n",
    "Class column having 0 indicates a normal transaction.\n",
    "Class column having 1 indicates a fraud transaction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c9d4e1f-96c3-45c7-a9f4-b08873696f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132bc695-140c-4fe1-9550-b720da915ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (284807, 31)\n",
      "Rows : 284807\n",
      "Columns : 31\n"
     ]
    }
   ],
   "source": [
    "# Getting the shape of the data\n",
    "print('Shape :', df.shape)\n",
    "print('Rows :', df.shape[0])\n",
    "print('Columns :', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16df1e80-111b-4dc3-ae3e-9e7fac4168c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2437347-8b04-4c0a-bb54-540d6b3771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c19037e4-3fb0-420a-a619-b3bf2d77ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd642679-4c7f-4dba-82fe-a38e13c15434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about null values\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85a64b85-8353-461f-a7ee-15a1e1e856db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the amount column\n",
    "df['normAmount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\n",
    "\n",
    "# Dropping the columns\n",
    "df.drop(['Time', 'Amount'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3320add-459e-48cb-a4aa-53001d046cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.9983\n",
       "1    0.0017\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the proportion of values from 'Class' column\n",
    "df['Class'].value_counts(normalize = True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd2731-9f72-47c8-b24a-25e29bff154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 99.83% of the data from Class 0\n",
    "# We have 0.17% of the data from Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc7446-6083-43a1-a193-7807cd0b6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above data indicates that there is a huge amount of imbaalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4de2c842-c9e9-4604-bcb0-d8d3c972531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating input features and target variable\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "# Performing train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1876c664-2b5a-420e-98f7-bb89a8f8f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 1.0\n",
      "Testing Precision : 0.77\n",
      "Testing Recall : 0.78\n",
      "Testing F1 Score : 0.78\n",
      "Testing AUC-ROC Score : 0.89\n",
      "\n",
      "Training Accuracy : 1.0\n",
      "Training Precision : 1.0\n",
      "Training Recall : 1.0\n",
      "Training F1 Score : 1.0\n",
      "Training AUC-ROC Score : 1.0\n",
      "\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.77      0.78      0.78        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.89      0.89      0.89     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=55)\n",
    "\n",
    "# Fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Getting probability predictions for AUC-ROC calculation\n",
    "y_prob_test = clf.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (1)\n",
    "y_prob_train = clf.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Model Evaluation - Testing Dataset\n",
    "print('Testing Accuracy :', np.round(metrics.accuracy_score(y_test, y_pred), 2))\n",
    "print('Testing Precision :', np.round(metrics.precision_score(y_test, y_pred), 2))\n",
    "print('Testing Recall :', np.round(metrics.recall_score(y_test, y_pred), 2))\n",
    "print('Testing F1 Score :', np.round(metrics.f1_score(y_test, y_pred), 2))\n",
    "print('Testing AUC-ROC Score :', np.round(metrics.roc_auc_score(y_test, y_prob_test), 2))\n",
    "\n",
    "# Model Evaluation - Training Dataset\n",
    "print('\\nTraining Accuracy :', np.round(metrics.accuracy_score(y_train, y_train_pred), 2))\n",
    "print('Training Precision :', np.round(metrics.precision_score(y_train, y_train_pred), 2))\n",
    "print('Training Recall :', np.round(metrics.recall_score(y_train, y_train_pred), 2))\n",
    "print('Training F1 Score :', np.round(metrics.f1_score(y_train, y_train_pred), 2))\n",
    "print('Training AUC-ROC Score :', np.round(metrics.roc_auc_score(y_train, y_prob_train), 2))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n Classification Report:\\n\", metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f590-c4e4-456c-8340-69e1b5531490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The model achieves 100% accuracy on both training and test data, suggesting overfitting, \n",
    "meaning it may have memorized patterns rather than generalizing well. \n",
    "While it performs well overall, its precision (0.77) means 23% of the predicted fraud cases were actually non-fraud (false positives). \n",
    "The recall (0.78) indicates that 22% of actual fraud cases were missed (false negatives), which can be risky in fraud detection.\n",
    "The high weighted average (1.00) is due to the overwhelming number of non-fraud cases (Class 0), making the overall performance appear perfect.\n",
    "To improve, we can focus on reducing overfitting and increasing recall to capture more fraud cases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aa61a1a-feb6-4279-b03a-95cecaed4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE, count of label 1 : 381\n",
      "Before SMOTE, count of label 0 : 226599\n",
      "\n",
      "After SMOTE, count of label 1 : 226599\n",
      "After SMOTE, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE to handle imbalance in the data\n",
    "print('Before SMOTE, count of label 1 :', sum(y_train == 1))\n",
    "print('Before SMOTE, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 5)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print('\\nAfter SMOTE, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After SMOTE, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "970b01dd-8575-4bce-b176-ab27f36e0fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Hyperparameters: {'min_samples_split': 10, 'min_samples_leaf': 10, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "\n",
      "Training Set Evaluation:\n",
      "Accuracy: 0.9987\n",
      "AUC-ROC Score: 1.0000\n",
      "Precision-Recall AUC: 1.0000\n",
      "\n",
      "Testing Set Evaluation:\n",
      "Accuracy: 0.9969\n",
      "AUC-ROC Score: 0.9229\n",
      "Precision-Recall AUC: 0.6421\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.33      0.85      0.47        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.66      0.92      0.73     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Optimized Model\n",
    "model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predictions for Training Set\n",
    "y_train_pred = model.predict(X_train_res)\n",
    "y_train_prob = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Predictions for Testing Set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Model Performance - Training Set\n",
    "train_accuracy = accuracy_score(y_train_res, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train_res, y_train_prob)\n",
    "train_precision, train_recall, _ = precision_recall_curve(y_train_res, y_train_prob)\n",
    "train_pr_auc = auc(train_recall, train_precision)\n",
    "\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {train_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {train_pr_auc:.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate Model Performance - Testing Set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_precision, test_recall, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "test_pr_auc = auc(test_recall, test_precision)\n",
    "\n",
    "print(\"\\nTesting Set Evaluation:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {test_pr_auc:.4f}\")\n",
    "print(\"\\nTesting Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948e49e-9763-47e7-88c5-2a2399f5af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Decision Tree model achieves near-perfect accuracy (0.9987) and AUC-ROC (1.0000) on the training set, indicating potential overfitting.\n",
    "On the test set, accuracy remains high (0.9969), but AUC-ROC drops to 0.9229, meaning the model is not generalizing as well.\n",
    "The recall for fraud cases (class 1) is high (0.85), indicating that the model detects most fraudulent transactions.\n",
    "However, precision for fraud cases is low (0.33), suggesting a high number of false positives,\n",
    "meaning many legitimate transactions are misclassified as fraud.\n",
    "The Precision-Recall AUC of 0.6421 suggests moderate effectiveness in distinguishing fraud cases,\n",
    "but the high discrepancy between training and testing performance confirms overfitting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12dd578f-0231-45ed-8e68-d939d5b6c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ADASYN, count of label 1 : 381\n",
      "Before ADASYN, count of label 0 : 226599\n",
      "\n",
      "After ADASYN, count of label 1 : 226630\n",
      "After ADASYN, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# ADASYN Sampling\n",
    "adasyn = ADASYN(random_state = 5)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Before ADASYN, count of label 1 :', sum(y_train == 1))\n",
    "print('Before ADASYN, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "print('\\nAfter ADASYN, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After ADASYN, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f6356b8-3ea6-44dd-80d0-2c96e6da0a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Hyperparameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 10, 'criterion': 'entropy'}\n",
      "\n",
      "Training Set Evaluation:\n",
      "Accuracy: 0.9780\n",
      "AUC-ROC Score: 0.9944\n",
      "Precision-Recall AUC: 0.9937\n",
      "\n",
      "Testing Set Evaluation:\n",
      "Accuracy: 0.9624\n",
      "AUC-ROC Score: 0.9310\n",
      "Precision-Recall AUC: 0.6189\n",
      "\n",
      "Testing Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56654\n",
      "           1       0.04      0.86      0.07        92\n",
      "\n",
      "    accuracy                           0.96     56746\n",
      "   macro avg       0.52      0.91      0.52     56746\n",
      "weighted avg       1.00      0.96      0.98     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# Train Optimized Model\n",
    "model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predictions for Training Set\n",
    "y_train_pred = model.predict(X_train_res)\n",
    "y_train_prob = model.predict_proba(X_train_res)[:, 1]\n",
    "\n",
    "# Predictions for Testing Set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Model Performance - Training Set\n",
    "train_accuracy = accuracy_score(y_train_res, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train_res, y_train_prob)\n",
    "train_precision, train_recall, _ = precision_recall_curve(y_train_res, y_train_prob)\n",
    "train_pr_auc = auc(train_recall, train_precision)\n",
    "\n",
    "print(\"\\nTraining Set Evaluation:\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {train_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {train_pr_auc:.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate Model Performance - Testing Set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "test_precision, test_recall, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "test_pr_auc = auc(test_recall, test_precision)\n",
    "\n",
    "print(\"\\nTesting Set Evaluation:\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {test_pr_auc:.4f}\")\n",
    "print(\"\\nTesting Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f52df-e9d8-40c9-97f4-da39efb4b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Set Performance: The model performs well on the training set with accuracy of 97.80%, AUC-ROC of 0.9944,\n",
    "and Precision-Recall AUC of 0.9937, indicating it has learned the patterns in the data effectively.\n",
    "Testing Set Performance: The test accuracy is 96.24%, but the AUC-ROC drops to 0.9310, showing a decline in generalization.\n",
    "Class Imbalance Issue: Precision for fraud cases (class 1) is only 0.04, \n",
    "meaning many non-fraud transactions are incorrectly flagged as fraud. \n",
    "However, recall is 0.86, which suggests the model detects a large portion of fraudulent cases.\n",
    "Precision-Recall Tradeoff: The F1-score for fraud is just 0.07, \n",
    "indicating an imbalance between precision and recall—too many false positives (misclassified legitimate transactions).\n",
    "Overfitting Concern: The difference in AUC-ROC (0.9944 in training vs. 0.9310 in testing)\n",
    "and drop in precision suggest that the model is slightly overfitting.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e74556-410d-4e81-bba2-462ca967fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
