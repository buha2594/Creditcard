{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ea24c0-d108-4b1f-bd2b-ced0626f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea321cb-3e6d-43da-bb6a-f9e3d17c4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/cdrive/desktop/DIVYA/CAREER/guvi/PROJECT/CREDIT_CARD/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba683e5-018b-438b-abe0-02b0a2290fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This data is about the credit card fraud transactions.\n",
    "Class column having 0 indicates a normal transaction.\n",
    "Class column having 1 indicates a fraud transaction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c9d4e1f-96c3-45c7-a9f4-b08873696f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "132bc695-140c-4fe1-9550-b720da915ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (284807, 31)\n",
      "Rows : 284807\n",
      "Columns : 31\n"
     ]
    }
   ],
   "source": [
    "# Getting the shape of the data\n",
    "print('Shape :', df.shape)\n",
    "print('Rows :', df.shape[0])\n",
    "print('Columns :', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16df1e80-111b-4dc3-ae3e-9e7fac4168c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2437347-8b04-4c0a-bb54-540d6b3771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19037e4-3fb0-420a-a619-b3bf2d77ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd642679-4c7f-4dba-82fe-a38e13c15434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about null values\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a64b85-8353-461f-a7ee-15a1e1e856db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the amount column\n",
    "df['normAmount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\n",
    "\n",
    "# Dropping the columns\n",
    "df.drop(['Time', 'Amount'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3320add-459e-48cb-a4aa-53001d046cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.9983\n",
       "1    0.0017\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the proportion of values from 'Class' column\n",
    "df['Class'].value_counts(normalize = True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd2731-9f72-47c8-b24a-25e29bff154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 99.83% of the data from Class 0\n",
    "# We have 0.17% of the data from Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc7446-6083-43a1-a193-7807cd0b6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above data indicates that there is a huge amount of imbaalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4de2c842-c9e9-4604-bcb0-d8d3c972531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating input features and target variable\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "# Performing train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1876c664-2b5a-420e-98f7-bb89a8f8f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Taking the predictions from the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "963262d1-90a8-4568-aeb8-2b2ffac22d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Performance\n",
      "Accuracy: 0.9991\n",
      "Precision: 0.8566\n",
      "Recall: 0.5801\n",
      "F1 Score: 0.6917\n",
      "AUC-ROC Score: 0.9778\n",
      "Precision-Recall AUC: 0.7338\n",
      "\n",
      " Test Set Performance**\n",
      "Accuracy: 0.9994\n",
      "Precision: 0.9028\n",
      "Recall: 0.7065\n",
      "F1 Score: 0.7927\n",
      "AUC-ROC Score: 0.9788\n",
      "Precision-Recall AUC: 0.8179\n",
      "\n",
      "Classification Report (Test Data)**\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.90      0.71      0.79        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.95      0.85      0.90     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc, classification_report\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Probabilities for AUC Calculation\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Model Performance on Training Set\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "train_prec = precision_score(y_train, y_train_pred)\n",
    "train_rec = recall_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_prob)\n",
    "precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_prob)\n",
    "train_pr_auc = auc(recall_train, precision_train)\n",
    "\n",
    "# Evaluate Model Performance on Test Set\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_prec = precision_score(y_test, y_test_pred)\n",
    "test_rec = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "test_pr_auc = auc(recall_test, precision_test)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\nTraining Set Performance\")\n",
    "print(f\"Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Precision: {train_prec:.4f}\")\n",
    "print(f\"Recall: {train_rec:.4f}\")\n",
    "print(f\"F1 Score: {train_f1:.4f}\")\n",
    "print(f\"AUC-ROC Score: {train_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {train_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\n Test Set Performance**\")\n",
    "print(f\"Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Precision: {test_prec:.4f}\")\n",
    "print(f\"Recall: {test_rec:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"AUC-ROC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Test Data)**\\n\", classification_report(y_test, y_test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f590-c4e4-456c-8340-69e1b5531490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The model demonstrates high accuracy (99.94%), but this is expected due to the class imbalance.\n",
    "The AUC-ROC (0.9788) and Precision-Recall AUC (0.8179) indicate strong overall performance. \n",
    "The recall on the test set (70.65%) suggests that the model is identifying fraudulent cases reasonably well,\n",
    "but there is still room for improvement. \n",
    "The precision (90.28%) shows that most flagged fraud cases are indeed fraudulent. \n",
    "The F1-score (79.27%) reflects a good balance between precision and recall\n",
    "The model performs slightly better on the test set than on the training set, suggesting minimal overfitting.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf1f0443-4148-481f-ba2e-b6afcb9957c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imblearn) (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\divya\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: imblearn\n",
      "Successfully installed imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# Installing required libraries\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aa61a1a-feb6-4279-b03a-95cecaed4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE, count of label 1 : 381\n",
      "Before SMOTE, count of label 0 : 226599\n",
      "\n",
      "After SMOTE, count of label 1 : 226599\n",
      "After SMOTE, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE to handle imbalance in the data\n",
    "print('Before SMOTE, count of label 1 :', sum(y_train == 1))\n",
    "print('Before SMOTE, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 5)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print('\\nAfter SMOTE, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After SMOTE, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "970b01dd-8575-4bce-b176-ab27f36e0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LogisticRegression Model (with handling class imbalance by SMOTE)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Taking the predictions from the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7500e92d-d70d-4356-b56d-0edc2777065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Set Performance\n",
      "Accuracy: 0.9725\n",
      "AUC-ROC Score: 0.9876\n",
      "Precision-Recall AUC: 0.7421\n",
      "\n",
      " Testing Set Performance\n",
      "Accuracy: 0.9727\n",
      "AUC-ROC Score: 0.9768\n",
      "Precision-Recall AUC: 0.8142\n",
      "\n",
      " Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56654\n",
      "           1       0.05      0.90      0.10        92\n",
      "\n",
      "    accuracy                           0.97     56746\n",
      "   macro avg       0.53      0.94      0.54     56746\n",
      "weighted avg       1.00      0.97      0.98     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Model Performance on Training Set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_prob)\n",
    "precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_prob)\n",
    "train_pr_auc = auc(recall_train, precision_train)\n",
    "\n",
    "# Evaluate Model Performance on Testing Set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "test_pr_auc = auc(recall_test, precision_test)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n Training Set Performance\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {train_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {train_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\n Testing Set Performance\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\n Classification Report (Test Data):\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1841a-b064-46d7-93ae-e33c05825819",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "High Accuracy (97.27%) but may be misleading due to the class imbalance.\n",
    "High Recall (0.90) for Fraud Cases, meaning the model detects most fraudulent transactions.\n",
    "Very Low Precision (0.05) leads to many false positives, incorrectly flagging legitimate transactions.\n",
    "AUC-ROC (0.9768) and PR-AUC (0.8142) indicate strong overall classification performance.\n",
    "Low F1-score (0.10) for Fraud Cases, showing poor balance between precision and recall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12dd578f-0231-45ed-8e68-d939d5b6c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ADASYN, count of label 1 : 381\n",
      "Before ADASYN, count of label 0 : 226599\n",
      "\n",
      "After ADASYN, count of label 1 : 226630\n",
      "After ADASYN, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# ADASYN Sampling\n",
    "adasyn = ADASYN(random_state = 5)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Before ADASYN, count of label 1 :', sum(y_train == 1))\n",
    "print('Before ADASYN, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "print('\\nAfter ADASYN, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After ADASYN, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8a4889f-0722-4e44-8ec2-c0fb77c30b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LogisticRegression Model (with handling class imbalance by ADASYN)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Taking the predictions from the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c67150b1-bce6-4cda-9f61-2b24ba5636e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Set Performance\n",
      "Accuracy: 0.9105\n",
      "AUC-ROC Score: 0.9884\n",
      "Precision-Recall AUC: 0.7620\n",
      "\n",
      " Testing Set Performance\n",
      "Accuracy: 0.9116\n",
      "AUC-ROC Score: 0.9729\n",
      "Precision-Recall AUC: 0.8221\n",
      "\n",
      " Classification Report (Test Data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     56654\n",
      "           1       0.02      0.95      0.03        92\n",
      "\n",
      "    accuracy                           0.91     56746\n",
      "   macro avg       0.51      0.93      0.49     56746\n",
      "weighted avg       1.00      0.91      0.95     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate Model Performance on Training Set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_roc_auc = roc_auc_score(y_train, y_train_prob)\n",
    "precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_prob)\n",
    "train_pr_auc = auc(recall_train, precision_train)\n",
    "\n",
    "# Evaluate Model Performance on Testing Set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "test_pr_auc = auc(recall_test, precision_test)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n Training Set Performance\")\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {train_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {train_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\n Testing Set Performance\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"AUC-ROC Score: {test_roc_auc:.4f}\")\n",
    "print(f\"Precision-Recall AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "print(\"\\n Classification Report (Test Data):\\n\", classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2b1b1-2e04-42a2-92bf-62971dfa95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy (91.16%) is lower compared to other models, as ADASYN generates synthetic minority samples, reducing the bias towards the majority class.\n",
    "Extremely High Recall (0.95) for Fraud Cases indicates the model detects almost all fraudulent transactions.\n",
    "Very Low Precision (0.02) means a high number of false positives, misclassifying many legitimate transactions as fraud.\n",
    "AUC-ROC (0.9729) and PR-AUC (0.8221) suggest good overall classification performance despite the low precision.\n",
    "Low F1-score (0.03) for Fraud Cases reflects an imbalance between precision and recall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6356b8-3ea6-44dd-80d0-2c96e6da0a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f52df-e9d8-40c9-97f4-da39efb4b7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e74556-410d-4e81-bba2-462ca967fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
