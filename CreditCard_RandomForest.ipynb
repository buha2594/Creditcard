{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ea24c0-d108-4b1f-bd2b-ced0626f4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea321cb-3e6d-43da-bb6a-f9e3d17c4550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"D:/cdrive/desktop/DIVYA/CAREER/guvi/PROJECT/CREDIT_CARD/creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba683e5-018b-438b-abe0-02b0a2290fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This data is about the credit card fraud transactions.\n",
    "Class column having 0 indicates a normal transaction.\n",
    "Class column having 1 indicates a fraud transaction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9d4e1f-96c3-45c7-a9f4-b08873696f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132bc695-140c-4fe1-9550-b720da915ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (284807, 31)\n",
      "Rows : 284807\n",
      "Columns : 31\n"
     ]
    }
   ],
   "source": [
    "# Getting the shape of the data\n",
    "print('Shape :', df.shape)\n",
    "print('Rows :', df.shape[0])\n",
    "print('Columns :', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16df1e80-111b-4dc3-ae3e-9e7fac4168c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2437347-8b04-4c0a-bb54-540d6b3771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the duplicate rows\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c19037e4-3fb0-420a-a619-b3bf2d77ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd642679-4c7f-4dba-82fe-a38e13c15434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an idea about null values\n",
    "df.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a64b85-8353-461f-a7ee-15a1e1e856db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the amount column\n",
    "df['normAmount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))\n",
    "\n",
    "# Dropping the columns\n",
    "df.drop(['Time', 'Amount'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3320add-459e-48cb-a4aa-53001d046cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.9983\n",
       "1    0.0017\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the proportion of values from 'Class' column\n",
    "df['Class'].value_counts(normalize = True).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd2731-9f72-47c8-b24a-25e29bff154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 99.83% of the data from Class 0\n",
    "# We have 0.17% of the data from Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc7446-6083-43a1-a193-7807cd0b6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above data indicates that there is a huge amount of imbaalance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de2c842-c9e9-4604-bcb0-d8d3c972531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating input features and target variable\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "# Performing train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1876c664-2b5a-420e-98f7-bb89a8f8f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the classifier\n",
    "clf = RandomForestClassifier(random_state = 5)\n",
    "\n",
    "# Fitting the data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Taking predictions from the model\n",
    "y_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6edb31c-fb30-4189-9b67-b913e68fd742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 1.0\n",
      "Testing Precision : 1.0\n",
      "Testing Recall : 1.0\n",
      "Testing F1 Score : 1.0\n",
      "\n",
      "Training Accuracy : 1.0\n",
      "Training Precision : 1.0\n",
      "Training Recall : 1.0\n",
      "Training F1 Score : 1.0\n",
      "\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.97      0.83      0.89        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.91      0.95     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model \n",
    "# Testing Performance\n",
    "print('Testing Accuracy :', np.round(metrics.accuracy_score(y_test, y_pred), 2))\n",
    "print('Testing Precision :', np.round(metrics.precision_score(y_test, y_pred, average = 'weighted'), 2))\n",
    "print('Testing Recall :', np.round(metrics.recall_score(y_test, y_pred, average = 'weighted'), 2))\n",
    "print('Testing F1 Score :', np.round(metrics.f1_score(y_test, y_pred, average = 'weighted'), 2))\n",
    "\n",
    "# Training Performance\n",
    "print('\\nTraining Accuracy :', np.round(metrics.accuracy_score(y_train, y_train_pred), 2))\n",
    "print('Training Precision :', np.round(metrics.precision_score(y_train, y_train_pred, average = 'weighted'), 2))\n",
    "print('Training Recall :', np.round(metrics.recall_score(y_train, y_train_pred, average = 'weighted'), 2))\n",
    "print('Training F1 Score :', np.round(metrics.f1_score(y_train, y_train_pred, average = 'weighted'), 2))\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4885f590-c4e4-456c-8340-69e1b5531490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random Forest model has achieved perfect accuracy (100%) on both training and testing data, indicating potential overfitting. \n",
    "The fraud class (1) has high precision (97%) and recall (83%), meaning it correctly identifies most fraud cases but still misses some. \n",
    "The macro average F1-score (0.95) and weighted average F1-score (1.00) suggest overall strong performance, \n",
    "but the model might be memorizing the training data rather than generalizing well.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1aa61a1a-feb6-4279-b03a-95cecaed4578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE, count of label 1 : 381\n",
      "Before SMOTE, count of label 0 : 226599\n",
      "\n",
      "After SMOTE, count of label 1 : 226599\n",
      "After SMOTE, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Using SMOTE to handle imbalance in the data\n",
    "print('Before SMOTE, count of label 1 :', sum(y_train == 1))\n",
    "print('Before SMOTE, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 5)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "print('\\nAfter SMOTE, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After SMOTE, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5481ec7e-4c06-4be7-80ea-e41714c940cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "\n",
      " Best Hyperparameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 93}\n",
      " Hyperparameter Tuning Time: 403.00 seconds\n",
      "\n",
      "\n",
      " Training Set Evaluation Metrics:\n",
      "Accuracy  : 1.0000\n",
      "Precision : 0.9719\n",
      "Recall    : 1.0000\n",
      "F1 Score  : 0.9858\n",
      "\n",
      " Testing Set Evaluation Metrics:\n",
      "Accuracy  : 0.9997\n",
      "Precision : 0.9868\n",
      "Recall    : 0.8152\n",
      "F1 Score  : 0.8929\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.99      0.82      0.89        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.91      0.95     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 100),         # Number of trees (50 to 100)\n",
    "    'max_depth': randint(5, 15),              # Tree depth (5 to 15)\n",
    "    'min_samples_split': randint(2, 10),      # Minimum samples to split a node\n",
    "    'min_samples_leaf': randint(1, 4),        # Minimum samples per leaf\n",
    "    'criterion': ['gini', 'entropy'],         # Splitting criteria\n",
    "    'class_weight': ['balanced', 'balanced_subsample']  # Handling Imbalance\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, \n",
    "    n_iter=10, cv=2, scoring='f1',  # Using F1-score due to class imbalance\n",
    "    n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "# Start Timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model (Required before accessing best_params_)**\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# End Timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Now Access Best Parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\n Best Hyperparameters:\", best_params)\n",
    "print(f\" Hyperparameter Tuning Time: {end_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "# Train Final Model with Best Parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"\\n Training Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"\\n Testing Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f52df-e9d8-40c9-97f4-da39efb4b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Random Forest model, optimized using RandomizedSearchCV and trained with SMOTE, demonstrates outstanding performance.\n",
    "The training accuracy is 100%, indicating perfect learning on the training data, which suggests potential overfitting. \n",
    "The testing accuracy remains very high at 99.97%, with strong precision (98.68%) \n",
    "and an F1-score of 89.29%, showing effective fraud detection.\n",
    "However, the recall for class 1 (fraud cases) is 81.52%, meaning some fraudulent transactions are still missed.\n",
    "The high precision ensures minimal false positives, making the model reliable for real-world deployment.\n",
    "Overall, the model performs exceptionally well, but slight overfitting is evident due to the gap between training and testing recall.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375db2d5-ebc8-40e2-ac54-4b47dc6d8536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ADASYN, count of label 1 : 381\n",
      "Before ADASYN, count of label 0 : 226599\n",
      "\n",
      "After ADASYN, count of label 1 : 226630\n",
      "After ADASYN, count of label 0 : 226599\n"
     ]
    }
   ],
   "source": [
    "# Importing important libraries\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# ADASYN Sampling\n",
    "adasyn = ADASYN(random_state = 5)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Before ADASYN, count of label 1 :', sum(y_train == 1))\n",
    "print('Before ADASYN, count of label 0 :', sum(y_train == 0))\n",
    "\n",
    "print('\\nAfter ADASYN, count of label 1 :', sum(y_train_res == 1))\n",
    "print('After ADASYN, count of label 0 :', sum(y_train_res == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a4c822-58d1-4696-a172-fdaa9bd11693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "\n",
      " Best Hyperparameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 14, 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 93}\n",
      " Hyperparameter Tuning Time: 450.06 seconds\n",
      "\n",
      "\n",
      " Training Set Evaluation Metrics:\n",
      "Accuracy  : 1.0000\n",
      "Precision : 0.9719\n",
      "Recall    : 1.0000\n",
      "F1 Score  : 0.9858\n",
      "\n",
      " Testing Set Evaluation Metrics:\n",
      "Accuracy  : 0.9997\n",
      "Precision : 0.9868\n",
      "Recall    : 0.8152\n",
      "F1 Score  : 0.8929\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.99      0.82      0.89        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.91      0.95     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define Hyperparameter Search Space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 100),         # Number of trees (50 to 100)\n",
    "    'max_depth': randint(5, 15),              # Tree depth (5 to 15)\n",
    "    'min_samples_split': randint(2, 10),      # Minimum samples to split a node\n",
    "    'min_samples_leaf': randint(1, 4),        # Minimum samples per leaf\n",
    "    'criterion': ['gini', 'entropy'],         # Splitting criteria\n",
    "    'class_weight': ['balanced', 'balanced_subsample']  # Handling Imbalance\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, \n",
    "    n_iter=10, cv=2, scoring='f1',  # Using F1-score due to class imbalance\n",
    "    n_jobs=-1, verbose=2, random_state=42\n",
    ")\n",
    "\n",
    "# Start Timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model (Required before accessing best_params_)**\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# End Timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Now Access Best Parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"\\n Best Hyperparameters:\", best_params)\n",
    "print(f\" Hyperparameter Tuning Time: {end_time - start_time:.2f} seconds\\n\")\n",
    "\n",
    "# Train Final Model with Best Parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_train_pred = best_rf.predict(X_train)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"\\n Training Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_train, y_train_pred):.4f}\")\n",
    "\n",
    "print(\"\\n Testing Set Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision : {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall    : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score  : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e76ca0-1b4b-4c46-946a-f4d0303d747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The Random Forest model, trained using ADASYN and optimized with RandomizedSearchCV, shows excellent performance.\n",
    "The training accuracy is 100%, indicating perfect learning, which may suggest slight overfitting.\n",
    "The testing accuracy remains very high at 99.97%, with strong precision (98.68%) and an F1-score of 89.29%.\n",
    "The recall for class 1 (fraud cases) is 81.52%, meaning some fraudulent cases are still missed, but overall detection is strong.\n",
    "The high precision ensures minimal false positives, making the model reliable.\n",
    "ADASYN has helped balance the dataset, improving minority class detection while maintaining high accuracy.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
